<!doctype html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <title>Data Science 101 - Chapter 2</title>

    <link rel="stylesheet" href="lib/reveal.css">
    <link rel="stylesheet" href="lib/theme/myplanet.css">
    <link rel="stylesheet" href="css/main.css">
    <!-- Theme used for syntax highlighting of code -->
    <link rel="stylesheet" href="lib/zenburn.css">
</head>
<body>
<div class="reveal pattern--random">
    <div class="slides">
        <section class="intro" id="intro">
            <div class="logo-wrapper">
                <div class="logo"><span class="visually-hidden">Data Science 101</span></div>
            </div>
        </section>
        <section class="title" id="title">
            <div class="grid-wrapper">
                <div class="header">
                    Khoa Công Nghệ Thông Tin <br/>
                    Trường Đại học Sư Phạm TP.HCM - Việt Nam
                </div>
                <div class="content">
                    <h1>Data Science 101</h1>
                    <div class="description" style="font-size: 1.8em;">
                        Phần 3.1. <br/>
                        Loại Dữ Liệu Tuần Tự<br/>
                        (Sequential Data)
                    </div>
                </div>
                <div class="credit">
                    <hr/>
                    <div class="label">Presented By</div>
                    <div class="name">Nguyễn Đặng Kim Khánh</div>
                    <div class="role">Giảng Viên trường ĐHSP TP.HCM</div>
                </div>
            </div>
        </section>
        <section class="team color--dark">
            <div class="grid-wrapper">
                <div class="header">Data Science 101 / Sequential Data</div>
                <div class="section">Khái Niệm Sequential Data</div>
                <div class="column" style="font-size: 1.8em;">
                    <div>
                        <ul>
                            <li>Sequential Data là dữ liệu mang tính chất chuỗi và mọi phần tử có thứ tự trước sau</li>
                            <li>Ví dụ: giá cổ phiếu của công ty theo từng ngày trong 1 năm, nhiệt độ thời tiết theo từng ngày trong 1 năm,
                                một câu văn, giọng nói, video, hình ảnh!?, ...</li>
                        </ul>
                    </div>
                    <div>
                        <img src="media/ecg.png" /><br/>
                        <div style="font-size: 0.4em; display: block">Rajpurkar, P., Hannun, A. Y., Haghpanahi, M., Bourn, C., & Ng, A. Y. (2017).
                            Cardiologist-level arrhythmia detection with convolutional neural networks. arXiv preprint arXiv:1707.01836.</div>
                    </div>
                </div>
            </div>
        </section>
        <section class="color--dark">
            <div class="grid-wrapper">
                <div class="header">Data Science 101 / Sequential Data</div>
                <div class="section">Mô Tả bằng Toán Học</div>
                <div class="column" style="font-size: 1.8em;">
                    <ul>
                        <li>Mỗi data sample $\textbf{x}_n$ của sequential data được mô tả như sau:</li>
                        \[\begin{aligned}
                        \textbf{x}_n=\left\{\textbf{x}_n^{\left(1\right)},\ldots,\textbf{x}_n^{\left(T_n\right)}\right\}
                        \end{aligned} \]
                        trong đó: <br/>
                        $\textbf{x}_n^{\left(t\right)}\in\mathcal{X},\forall n=1,\ldots,N;t=1,\ldots,T_n$<br/>
                        $T_1,\ldots,T_n$ có thể không giống nhau
                    </ul>
                </div>
            </div>
        </section>
        <section class="color--dark">
            <div class="grid-wrapper">
                <div class="header">Data Science 101 / Sequential Data</div>
                <div class="section">Tính Chất của Sequential Data</div>
                <div class="column" style="font-size: 1.8em;">
                    <ul>
                        <li style="margin-top: 0.5em;">Mỗi data sample có length ($T_n$) khác nhau</li>
                        <li style="margin-top: 0.5em;">Data ở step thứ $t$ có mối tương quan tới các steps trước đó hoặc sau đó. </li>
                        <li style="margin-top: 0.5em;">Data ở step thứ $t$ có mối tương quan rất chặt ở step thứ $t+1$ và $t-1$</li>
                    </ul>
                </div>
            </div>
        </section>
        <section class="color--dark">
            <div class="grid-wrapper">
                <div class="header">Data Science 101 / Sequential Data</div>
                <div class="section">Các Bài Toán trong Sequential Data</div>
                <div class="column" style="font-size: 1.7em;">
                    <ul>
                        <li>One-To-Many</li>
                        <ul>
                            <li>Input: sequential data có length = 1 | Output: sequential data có length > 1</li>
                            <li>Example: music/poem generation</li>
                        </ul>
                        <li>Many-To-One</li>
                        <ul>
                            <li>Input: sequential data có length = 1 | Output: sequential data có length > 1</li>
                            <li>Example: music/poem classification</li>
                        </ul>
                        <li>Many-To-Many</li>
                        <ul>
                            <li>Input: sequential data có length > 1 | Output: sequential data có length > 1</li>
                            <li>Example: name entity recognition (input & output có length giống nhau), translation (input & output có length khác nhau)</li>
                        </ul>
                    </ul>
                </div>
            </div>
        </section>
        <section class="subsection color--dark">
            <div class="grid-wrapper">
                <div class="header">Data Science 101 / Sequential Data</div>
                <h1>Recurrent Neural Networks (RNNs)</h1>
                <div class="description">
                    "Làm sao để ghi nhận mối quan hệ temporal giữa các steps?"
                </div>
            </div>
        </section>
        <section class="team color--dark">
            <div class="grid-wrapper">
                <div class="header">Data Science 101 / Sequential Data / RNNs</div>
                <div class="section">Kiến Trúc Tổng Quát của Traditional RNN</div>
                <div class="column" style="font-size: 1.3em;">
                    <div>
                        <ul>
                            <li>RNN gồm các nhiều hidden units liên kết liền kề nhau</li>
                            \[\begin{aligned}
                            \textbf{h}^{(t)}&=\phi_{h}\left(\textbf{U}\textbf{x}^{(t)}+\textbf{V}\textbf{h}^{(t-1)}+\textbf{b}_h\right) \\
                            \textbf{y}^{(t)}&=\phi_{y}\left(\textbf{W}\textbf{h}^{(t)}+\textbf{b}_y\right) \\
                            \end{aligned} \]
                            trong đó <br/>
                            <div style="font-size: 0.9em">
                            $\phi_{h}\left(\cdot\right)$ và $\phi_{y}\left(\cdot\right)$ là các hàm activation<br/>
                            $\textbf{U}$ có shape là $\left(h\times d\right)$, $\textbf{V}$ có shape là $\left(h\times h\right)$<br/>
                            $\textbf{x}^{(t)}$ có shape là $\left(d\times 1\right)$, $\textbf{h}^{(t)}$ có shape là $\left(h\times 1\right)$<br/>
                            $\textbf{b}_h$ có shape là $\left(h\times 1\right)$<br/>
                            $\textbf{W}$ có shape là $\left(c\times h\right)$, $\textbf{b}_y$ có shape là $\left(c\times 1\right)$<br/>
                            $\textbf{U}, \textbf{V}, \textbf{W}, \textbf{b}_h, \textbf{b}_y$ là những learnable parameters
                            </div>
                        </ul>
                    </div>
                    <div>
                        <img style="background-color: white;" src="media/rnn.png" /><br/>
                        <div style="font-size: 0.4em; display: block;">https://en.wikipedia.org/wiki/Recurrent_neural_network</div>
                    </div>
                </div>
            </div>
        </section>
        <section class="color--dark">
            <div class="grid-wrapper">
                <div class="header">Data Science 101 / Sequential Data / RNNs</div>
                <div class="section">Cách Xây Dựng RNN (Many-To-One)</div>
                <div class="main" style="font-size: 1.8em;">
                    <ul>
                        <li>Ta sẽ sử dụng SimpleRNN layer. Tham số <code>units</code> chính là $h$ trong công thức</li>
                        <pre><code class="python hljs" data-trim data-noescape>
        from tensorflow.keras.layers import Input, SimpleRNN, Dense
        input_layer = Input([10, 128])
        rnn_layer = SimpleRNN(units=64)(input_layer)
        output_layer = Dense(4)(rnn_layer)
        model = Model(input_layer, output_layer)
                        </code></pre>
                        <pre><code class="python hljs" data-trim data-noescape>
        _________________________________________________________________
        Layer (type)                 Output Shape              Param #
        =================================================================
        input_1 (InputLayer)        [(None, 10, 128)]         0
        _________________________________________________________________
        simple_rnn_1 (SimpleRNN)    (None, 64)                12352
        _________________________________________________________________
        dense_1 (Dense)             (None, 4)                 260
        =================================================================
        Total params: 12,612
        Trainable params: 12,612
        Non-trainable params: 0
        _________________________________________________________________
                        </code></pre>
                    </ul>
                </div>
            </div>
        </section>
        <section class="color--dark">
            <div class="grid-wrapper">
                <div class="header">Data Science 101 / Sequential Data / RNNs</div>
                <div class="section">Cách Xây Dựng RNN (Many-To-Many)</div>
                <div class="main" style="font-size: 1.8em;">
                    <ul>
                        <li>Ta thêm tham số <code>return_sequences=True</code></li>
                        <pre><code class="python hljs" data-trim data-noescape>
        from tensorflow.keras.layers import Input, SimpleRNN, Dense
        input_layer = Input([10, 128])
        rnn_layer = SimpleRNN(units=64, return_sequences=True)(input_layer)
        output_layer = Dense(4)(rnn_layer)
        model = Model(input_layer, output_layer)
                        </code></pre>
                        <pre><code class="python hljs" data-trim data-noescape>
        _________________________________________________________________
        Layer (type)                 Output Shape              Param #
        =================================================================
        input_1 (InputLayer)        [(None, 10, 128)]         0
        _________________________________________________________________
        simple_rnn_1 (SimpleRNN)    (None, 10, 64)            12352
        _________________________________________________________________
        dense_1 (Dense)             (None, 10, 4)             260
        =================================================================
        Total params: 12,612
        Trainable params: 12,612
        Non-trainable params: 0
                        </code></pre>
                    </ul>
                </div>
            </div>
        </section>
        <section class="color--dark">
            <div class="grid-wrapper">
                <div class="header">Data Science 101 / Sequential Data / RNNs</div>
                <div class="section">Tính Chất của Traditional RNN</div>
                <div class="main" style="font-size: 1.8em;">
                    <ul>
                        <li>Thông tin ở các time steps trước step $t$ được encode trong $\textbf{h}^{(t)}$</li>
                        <li>Có thể handle sequential data với bất kì length</li>
                        <li>Số lượng parameters/weights không tăng khi length của sequence tăng</li>
                        <li>Dễ bị gradient vanishing and exploding</li>
                    </ul>
                </div>
            </div>
        </section>
        <section class="color--dark">
            <div class="grid-wrapper">
                <div class="header">Data Science 101 / Sequential Data / RNNs</div>
                <div class="section">Long Short Term Memory (LSTM) Cell </div>
                <div class="main" style="font-size: 1.4em;">
                    <ul>
                        <li>LSTM thay thế network giữa input và hidden state</li>
                        <li>LSTM có cell state và các cổng (gate) để điều khiển thông tin cần giữ lại để truyền cho các cells tiếp theo </li>
                        <li>Cách viết code tương tự như <code>SimpleRNN</code>, chỉ cần thay <code>SimpleRNN</code> bằng <code>LSTM</code></li>
                    </ul>
                    <div style="margin-top: 1em;">
                        <img style="background-color: white; width: 48%; display: inline-block" src="media/LSTM3-SimpleRNN.png" />
                        <img style="background-color: white; width: 48%; display: inline-block" src="media/LSTM3-chain.png" />
                    </div>
                    <span style="font-size: 0.4em; display: block;">http://colah.github.io/posts/2015-08-Understanding-LSTMs/</span>
                </div>
            </div>
        </section>
        <section class="team color--dark">
            <div class="grid-wrapper">
                <div class="header">Data Science 101 / Sequential Data / RNNs</div>
                <div class="section">Gated Recurrent Unit (GRU) Cell </div>
                <div class="column" style="font-size: 1.8em;">
                    <div>
                        <li>Đây là 1 biến thể của LSTM</li>
                        <li>Khác với LSTM, GRU không có cell state và số lượng parameters ít hơn</li>
                        <li>Cách viết code tương tự như <code>SimpleRNN</code>, chỉ cần thay <code>SimpleRNN</code> bằng <code>GRU</code></li>
                    </div>
                    <div>
                        <img src="media/LSTM3-var-GRU.png" style="width: 15em; background-color: whitesmoke"/>
                        <span style="font-size: 0.4em; display: block;">https://colah.github.io/posts/2015-08-Understanding-LSTMs</span>
                    </div>
                </div>
            </div>
        </section>
        <section class="subsection color--dark">
            <div class="grid-wrapper">
                <div class="header">Data Science 101 / Sequential Data</div>
                <h1>Bidirectional Recurrent Neural Network</h1>
                <div class="description">
                    "Có khi nào <i>tương lai</i> lại ảnh hưởng tới <i>quá khứ</i>?"
                </div>
            </div>
        </section>
        <section class="team color--dark">
            <div class="grid-wrapper">
                <div class="header">Data Science 101 / Sequential Data / Bi-RNNs</div>
                <div class="section">Kiến Trúc Bidirectional RNN</div>
                <div class="column" style="font-size: 1.8em;">
                    <div>
                        <li>Dùng cho những loại dữ liệu có tác động ảnh hưởng 2 chiều</li>
                        <li>Gồm 2 RNNs cùng nhận input như nhau nhưng: 1) theo chiều từ trái qua phải, 2) theo chiều từ phải sang trái</li>
                        <li>Hidden state của 2 RNNs có thể cộng (sum) hoặc ghép (concatenate) hoặc nhân (dot product) hoặc trung bình (average)</li>
                    </div>
                    <div>
                        <img src="media/BiRNN.png" style="width: 15em; background-color: whitesmoke"/>
                        <span style="font-size: 0.4em; display: block;">
                            Graves, Alex, Navdeep Jaitly, and Abdel-rahman Mohamed. "Hybrid speech recognition with deep bidirectional LSTM."
                            IEEE workshop on automatic speech recognition and understanding. IEEE, 2013.
                        </span>
                    </div>
                </div>
            </div>
        </section>
        <section class="color--dark">
            <div class="grid-wrapper">
                <div class="header">Data Science 101 / Sequential Data / Bi-RNNs</div>
                <div class="section">Cách Xây Dựng Bidirectional RNN (Many-To-Many)</div>
                <div class="main" style="font-size: 1.5em;">
                    <ul>
                        <li>Ta sử dụng <code>Bidirectional</code> và truyền vào tên RNN network (SimpleRNN, LSTM, GRU) và <code>merge_mode</code></li>
                        <pre><code class="python hljs" data-trim data-noescape>
        from tensorflow.keras.layers import Input, LSTM, Dense, Bidirectional
        input_layer = Input([10, 128])
        bi_rnn_layer = Bidirectional(LSTM(units=64, return_sequences=True), merge_mode='concat')(input_layer)
        output_layer = Dense(4)(bi_rnn_layer)
        model = Model(input_layer, output_layer)
                        </code></pre>
                        <pre><code class="python hljs" data-trim data-noescape>
        _________________________________________________________________
        Layer (type)                 Output Shape              Param #
        =================================================================
        input_1 (InputLayer)         [(None, 10, 128)]         0
        _________________________________________________________________
        bidirectional_1 (Bidirection (None, 10, 128)           98816
        _________________________________________________________________
        dense_1 (Dense)              (None, 10, 4)             516
        =================================================================
        Total params: 99,332
        Trainable params: 99,332
        Non-trainable params: 0
                        </code></pre>
                    </ul>
                </div>
            </div>
        </section>
        <section class="subsection color--dark">
            <div class="grid-wrapper">
                <div class="header">Data Science 101 / Sequential Data</div>
                <h1>Deep (Bidirectional) Recurrent Neural Network</h1>
                <div class="description">
                </div>
            </div>
        </section>
        <section class="color--dark">
            <div class="grid-wrapper">
                <div class="header">Data Science 101 / Sequential Data / Deep RNNs</div>
                <div class="section">Cách Xây Dựng Deep (Bidirectional) RNN (Many-To-Many)</div>
                <div class="main" style="font-size: 1.7em;">
                    <ul>
                        <li>Mỗi RNN sẽ output ra 1 sequence, do đó có thể dùng nó để input vào 1 RNN khác</li>
                        <pre><code class="python hljs" data-trim data-noescape>
        from tensorflow.keras.layers import Input, LSTM, Dense
        input_layer = Input([10, 128])
        rnn_layer_1 = LSTM(units=64, return_sequences=True)(input_layer)
        rnn_layer_2 = LSTM(units=32, return_sequences=True)(rnn_layer_1)
        output_layer = Dense(4)(rnn_layer_2)
        model = Model(input_layer, output_layer)
                        </code></pre>
                        <pre><code class="python hljs" data-trim data-noescape>
        _________________________________________________________________
        Layer (type)                 Output Shape              Param #
        =================================================================
        input_1 (InputLayer)         [(None, 10, 128)]         0
        _________________________________________________________________
        lstm_1 (LSTM)                (None, 10, 64)            49408
        _________________________________________________________________
        lstm_2 (LSTM)                (None, 10, 32)            12416
        _________________________________________________________________
        dense_1 (Dense)              (None, 10, 4)             132
        =================================================================
        Total params: 61,956
        Trainable params: 61,956
        Non-trainable params: 0
                        </code></pre>
                    </ul>
                </div>
            </div>
        </section>
        <section class="subsection color--dark">
            <div class="grid-wrapper">
                <div class="header">Data Science 101 / Sequential Data</div>
                <h1>Sequence to Sequence (Seq2Seq)</h1>
                <div class="description">
                </div>
            </div>
        </section>
        <section class="team color--dark">
            <div class="grid-wrapper">
                <div class="header">Data Science 101 / Sequential Data / Seq2Seq</div>
                <div class="section">Kiến Trúc Seq2Seq</div>
                <div class="column" style="font-size: 1.8em;">
                    <div>
                        <li>Dùng cho bài toán many-to-many với độ dài input & ouput khác nhau</li>
                        <li>Gồm 2 RNNs:</li>
                        <ul>
                            <li>RNN Encoder để encode chuỗi input</li>
                            <li>RNN Decoder để decode chuỗi output</li>
                        </ul>
                    </div>
                    <div>
                        <img src="media/seq2seq_new.png" style="width: 15em; background-color: whitesmoke"/>
                        <span style="font-size: 0.4em; display: block;">
                            Esmaili, K. S.. “Attention-based Encoder-Decoder Networks for Spelling and Grammatical Error Correction.” (2017).
                        </span>
                    </div>
                </div>
            </div>
        </section>
        <section class="team color--dark">
            <div class="grid-wrapper">
                <div class="header">Data Science 101 / Sequential Data / Seq2Seq</div>
                <div class="section">Kiến Trúc Seq2Seq with Attention Layer</div>
                <div class="column" style="font-size: 1.8em;">
                    <div>
                        <li>Attention layer là 1 tầng cho biết các trọng số cho từng time step của chuỗi input trong quá trình decode</li>
                        <li>Attention layer giúp định hướng thông tin của time step nào trong chuỗi input tác động trực tiếp đến time step nào ở chuỗi output </li>
                    </div>
                    <div>
                        <img src="media/seq2seq_attention.png" style="width: 15em; background-color: whitesmoke"/>
                        <span style="font-size: 0.4em; display: block;">
                            Esmaili, K. S.. “Attention-based Encoder-Decoder Networks for Spelling and Grammatical Error Correction.” (2017).
                        </span>
                    </div>
                </div>
            </div>
        </section>
        <section class="subsection color--dark">
            <div class="grid-wrapper">
                <div class="header">Data Science 101</div>
                <h1>Thắc Mắc và Trao Đổi</h1>
                <div class="description">
                </div>
            </div>
        </section>
    </div>
</div>
<script src="lib/head.min.js"></script>
<script src="lib/reveal.js"></script>
<script src="lib/plugin/math/math.js"></script>
<script src="lib/plugin/highlight/highlight.js"></script>
<script src="lib/reveal-init.js"></script>
</body>
</html>